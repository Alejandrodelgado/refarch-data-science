{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"left\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Lab: Build, Save and Deploy Model to IBM Watson Machine Learning (WML)</b></th>\n",
    "      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook walks you through these steps:\n",
    "- Build a model\n",
    "- Save the model in the WML repository\n",
    "- Create a Deployment in WML\n",
    "- Invoke the deployed model with a Rest Client to test it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Connect to dashDB and load CUSTOMER table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Replace dashDB connection information for loading data from Customer and Churn tables prior to running the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the required API and instantiate Spark Context\n",
    "from ingest.Connectors import Connectors\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sparkSession = SparkSession.builder.master(\"local\").appName(\"spark session example\").getOrCreate()\n",
    "\n",
    "# IMPORTANT: Replace all values with values in your dashDB instance\n",
    "customerTable = { Connectors.DASHDB.HOST              : 'dashdb-entry-yp-dal09-09.services.dal.bluemix.net',\n",
    "                      Connectors.DASHDB.DATABASE          : 'BLUDB',\n",
    "                      Connectors.DASHDB.USERNAME          : 'dash9737',\n",
    "                      Connectors.DASHDB.PASSWORD          : 'gDO~np@2IKj4',\n",
    "                      Connectors.DASHDB.SOURCE_TABLE_NAME : 'DASH9737.CUSTOMER'}\n",
    "\n",
    "customer = sparkSession.read.format(\"com.ibm.spark.discover\").options(**customerTable).load()\n",
    "customer.printSchema()\n",
    "customer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Connect to dashDB and load CHURN table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Replace all values with values in your dashDB instance\n",
    "churnTable = { Connectors.DASHDB.HOST              : 'dashdb-entry-yp-dal09-09.services.dal.bluemix.net',\n",
    "                      Connectors.DASHDB.DATABASE          : 'BLUDB',\n",
    "                      Connectors.DASHDB.USERNAME          : 'dash9737',\n",
    "                      Connectors.DASHDB.PASSWORD          : 'gDO~np@2IKj4',\n",
    "                      Connectors.DASHDB.SOURCE_TABLE_NAME : 'DASH9737.CHURN'}\n",
    "\n",
    "customer_churn = sparkSession.read.format(\"com.ibm.spark.discover\").options(**churnTable).load()\n",
    "customer_churn.printSchema()\n",
    "customer_churn.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Merge Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged=customer.join(customer_churn,customer['ID']==customer_churn['ID']).select(customer['*'],customer_churn['CHURN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Rename some columns\n",
    "This step is to remove spaces from columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = merged.withColumnRenamed(\"Est Income\", \"EstIncome\").withColumnRenamed(\"Car Owner\",\"CarOwner\")\n",
    "merged.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Build the Spark pipeline and the Random Forest model\n",
    "\"Pipeline\" is an API in SparkML that's used for building models.\n",
    "Additional information on SparkML: https://spark.apache.org/docs/2.0.2/ml-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Prepare string variables so that they can be used by the decision tree algorithm\n",
    "stringIndexer1 = StringIndexer(inputCol='Gender', outputCol='GenderEncoded')\n",
    "stringIndexer2 = StringIndexer(inputCol='Status',outputCol='StatusEncoded')\n",
    "stringIndexer3 = StringIndexer(inputCol='CarOwner',outputCol='CarOwnerEncoded')\n",
    "stringIndexer4 = StringIndexer(inputCol='Paymethod',outputCol='PaymethodEncoded')\n",
    "stringIndexer5 = StringIndexer(inputCol='LocalBilltype',outputCol='LocalBilltypeEncoded')\n",
    "stringIndexer6 = StringIndexer(inputCol='LongDistanceBilltype',outputCol='LongDistanceBilltypeEncoded')\n",
    "stringIndexer7 = StringIndexer(inputCol='CHURN', outputCol='label')\n",
    "\n",
    "# Pipelines API requires that input variables are passed in  a vector\n",
    "assembler = VectorAssembler(inputCols=[\"GenderEncoded\", \"StatusEncoded\", \"CarOwnerEncoded\", \"PaymethodEncoded\", \"LocalBilltypeEncoded\", \\\n",
    "                                       \"LongDistanceBilltypeEncoded\", \"Children\", \"EstIncome\", \"Age\", \"LongDistance\", \"International\", \"Local\",\\\n",
    "                                      \"Dropped\",\"Usage\",\"RatePlan\"], outputCol=\"features\")\n",
    "\n",
    "\n",
    "# instantiate the algorithm, take the default settings\n",
    "rf=RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "#pipeline = Pipeline(stages=[stringIndexer1, stringIndexer2, stringIndexer3, assembler, rf])\n",
    "pipeline = Pipeline(stages=[stringIndexer1,stringIndexer2,stringIndexer3,stringIndexer4,stringIndexer5,stringIndexer6,stringIndexer7, assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into train and test datasets\n",
    "train, test = merged.randomSplit([0.8,0.2], seed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build models\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 6: Score the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Precision model1 = {:.2f}.'.format(results.filter(results.label == results.prediction).count() / float(results.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "print 'Area under ROC curve = {:.2f}.'.format(evaluator.evaluate(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Save Model in WML repository\n",
    "\n",
    "In this section you will store your model in the Watson Machine Learning (WML) repository by using Python client libraries.\n",
    "* <a href=\"https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html\">WML Documentation</a>\n",
    "* <a href=\"http://watson-ml-api.mybluemix.net/\">WML API</a> \n",
    "<br/>\n",
    "\n",
    "First, you must import client libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from repository.mlrepositoryclient import MLRepositoryClient\n",
    "from repository.mlrepositoryartifact import MLRepositoryArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your authentication information from your instance of the Watson Machine Learning service in <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> in the next cell. You can find your information on the **Service Credentials** tab of your service instance in Bluemix.\n",
    "\n",
    "<span style=\"color:red\">Replace the service_path and credentials with your own information</span>\n",
    "\n",
    "service_path=[your url]<br/>\n",
    "username=[your username]<br/>\n",
    "password=[your password]<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service_path = 'https://ibm-watson-ml.mybluemix.net'\n",
    "username = 'db7336ae-b258-4b0c-9bd2-57ca9d090f08'\n",
    "password = 'ff129993-058d-472b-bbcb-edf40568b6c8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorize the repository client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_repository_client = MLRepositoryClient(service_path)\n",
    "ml_repository_client.authorize(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model artifact (abstraction layer).\n",
    "\n",
    "<b>Tip:</b> The MLRepositoryArtifact method expects a trained model object, training data, and a model name. (It is this model name that is displayed by the Watson Machine Learning service).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artifact = MLRepositoryArtifact(model, training_data=train, name=\"Predict Customer Churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pipeline and model artifacts to your Watson Machine Learning instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_model = ml_repository_client.models.save(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the saved model properties\n",
    "print \"modelType: \" + saved_model.meta.prop(\"modelType\")\n",
    "print \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\n",
    "print \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\n",
    "print \"label: \" + saved_model.meta.prop(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9:  Generate Authorization Token for Invoking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib3, requests, json\n",
    "\n",
    "headers = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\n",
    "url = '{}/v2/identity/token'.format(service_path)\n",
    "response = requests.get(url, headers=headers)\n",
    "mltoken = json.loads(response.text).get('token')\n",
    "print mltoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9.1 Copy the generated token into your notepad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10:  Go to WML in Bluemix to create a Deployment Endpoint and Test the Deployed model\n",
    "\n",
    "* In your <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> dashboard, click into your WML Service and click the **Launch Dashboard** button under Watson Machine Learing.\n",
    "![WML Launch Dashboard](https://raw.githubusercontent.com/yfphoon/dsx_demo/master/WML_Launch_Dashboard.png)\n",
    "\n",
    "<br/>\n",
    "* You should see your deployed model in the **Models** tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Under *Actions*, click on the 3 ellipses and click ***Create Deployment***.  Give your deployment configuration a unique name, e.g. \"Predict Customer Churn Deply\", accept the defaults and click **Save**.\n",
    "<br/>\n",
    "<br/>\n",
    "* In the *Deployments tab*, under *Actions*, click **View Details**\n",
    "<br/>\n",
    "<br/>\n",
    "* Scoll down to **API Details**, copy the value of the **Scoring Endpoint** into your notepad.  (e.g. https://ibm-watson-ml.mybluemix.net/v2/published_models/64fd0462-3f8a-4b42-820b-59a4da9b7dc6/deployments/7d9995ed-7daf-4cfd-b40f-37cb8ab3d88f/online)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11:  Invoke the model with a REST Client, e.g. https://client.restlet.com/\n",
    "\n",
    "In the REST client interface enter the following information:\n",
    "\n",
    "1. Protocol:  **HTTPS**\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "2. URI: **your scoring endpoint**  (Step 10)\n",
    "<br/>\n",
    "<br/>\n",
    "3. method: **POST**\n",
    "<br/>\n",
    "<br/>\n",
    "4. Authorization:  **your generated token** (Step 9). Hint: Add \"Basic authorization\" with a dummy value of 1 in the userid field. Then replace the value with the token. \n",
    "<br/>\n",
    "<br/>\n",
    "5. Content Type: **application/JSON**\n",
    "<br/>\n",
    "<br/>\n",
    "6. JSON Body:<br/>**{\n",
    "  \"fields\": [\n",
    "    \"ID\",\"Gender\",\"Status\",\"Children\",\"EstIncome\",\"CarOwner\",\"Age\",\"LongDistance\",\"International\",\"Local\",\"Dropped\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\",\"Usage\",\"RatePlan\"\n",
    "  ],\n",
    "  \"values\": [ \n",
    "  [999,\"F\",\"M\",2.0,77551.100000,\"Y\",33.600000,20.530000,0.000000,41.890000,1.000000,\"CC\",\"Budget\",\"Intnl_discount\",62.420000,2.000000]\n",
    "  ]\n",
    "} **\n",
    "<br/>\n",
    "<br/>\n",
    "7. Click **Send*\n",
    "\n",
    "Scroll down to the **RESPONSE** section to see the scored results\n",
    "\n",
    "**Note:** The values in the JSON body does not include the label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You have come to the end of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Sidney Phoon**\n",
    "<br/>\n",
    "yfphoon@us.ibm.com\n",
    "<br/>\n",
    "April 25, 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}